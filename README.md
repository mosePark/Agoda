## Does a Large Language Model Really Speak in Human-Like Language?

[[arXiv link](https://arxiv.org/abs/2501.01273)]  
[[Published Version at STAT](https://onlinelibrary.wiley.com/doi/full/10.1002/sta4.70060)]

---

## 🔍 Overview

Despite the growing fluency of large language models (LLMs), there is still limited understanding of how “human-like” their language actually is.  
This study examines whether LLMs produce text that **structurally resembles human-written language** — not just on the surface, but in deeper patterns such as discourse structure and word usage communities.

We develop a statistical framework to evaluate these differences by comparing:

- **Original human-written reviews**
- **Paraphrased versions generated by GPT-3.5**
- **Paraphrased outputs that were passed through the model twice**

The analysis is based on textual data embedding and structural comparisons of writing style and variation patterns.

---

## 🔬 What We Did

- Collected a large dataset of customer reviews written by humans.
- Used GPT-3.5 to paraphrase these reviews once, then again.
- Compared the patterns and structures among the original, once-paraphrased, and twice-paraphrased texts.
- Focused on **community structure** — groupings of similar expressions and themes — within each corpus.
- Measured the **distance between these groupings** to assess whether LLMs are simply repeating patterns or truly mimicking human variation.

---

## 🧠 Key Insights

- LLM-generated texts are **fluent but structurally different** from human writing.
- Even small shifts in diversity parameters (like temperature) don't eliminate this difference — they only reduce it slightly.
- Paraphrasing LLM-generated text repeatedly does not lead to human-like results. Instead, it tends to reinforce non-human-like structures.
- This suggests that LLMs do not fully replicate the nuanced, organic variability of human language.

---

## 📁 Datasets Used

- **Human-written reviews** (originals)
- **GPT-3.5 paraphrased reviews**
- **Double-paraphrased outputs** (GPT → GPT)
- Additional benchmark corpora like CNN/DailyMail, SQuAD2, and Quora used for robustness checks

---

## 🧾 Citation

```bibtex
@article{park2024llm,
  title={Does a Large Language Model Really Speak in Human-Like Language?},
  author={Park, Mose and Choi, Yunjin and Jeon, Jong-June},
  journal={arXiv preprint arXiv:2501.01273},
  year={2024}
}
```

---

## 📄 License

